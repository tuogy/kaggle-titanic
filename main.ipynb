{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"        PassengerId    Survived      Pclass                  Name   Sex  \\\ncount    891.000000  891.000000  891.000000                   891   891   \nunique          NaN         NaN         NaN                   891     2   \ntop             NaN         NaN         NaN  Slabenoff, Mr. Petco  male   \nfreq            NaN         NaN         NaN                     1   577   \nmean     446.000000    0.383838    2.308642                   NaN   NaN   \nstd      257.353842    0.486592    0.836071                   NaN   NaN   \nmin        1.000000    0.000000    1.000000                   NaN   NaN   \n25%      223.500000    0.000000    2.000000                   NaN   NaN   \n50%      446.000000    0.000000    3.000000                   NaN   NaN   \n75%      668.500000    1.000000    3.000000                   NaN   NaN   \nmax      891.000000    1.000000    3.000000                   NaN   NaN   \n\n               Age       SibSp       Parch Ticket        Fare Cabin Embarked  \ncount   714.000000  891.000000  891.000000    891  891.000000   204      889  \nunique         NaN         NaN         NaN    681         NaN   147        3  \ntop            NaN         NaN         NaN   1601         NaN    G6        S  \nfreq           NaN         NaN         NaN      7         NaN     4      644  \nmean     29.699118    0.523008    0.381594    NaN   32.204208   NaN      NaN  \nstd      14.526497    1.102743    0.806057    NaN   49.693429   NaN      NaN  \nmin       0.420000    0.000000    0.000000    NaN    0.000000   NaN      NaN  \n25%      20.125000    0.000000    0.000000    NaN    7.910400   NaN      NaN  \n50%      28.000000    0.000000    0.000000    NaN   14.454200   NaN      NaN  \n75%      38.000000    1.000000    0.000000    NaN   31.000000   NaN      NaN  \nmax      80.000000    8.000000    6.000000    NaN  512.329200   NaN      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>204</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>891</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>681</td>\n      <td>NaN</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Slabenoff, Mr. Petco</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1601</td>\n      <td>NaN</td>\n      <td>G6</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>644</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>NaN</td>\n      <td>32.204208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>NaN</td>\n      <td>49.693429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.910400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}],"source":["train_data = pd.read_csv('data/train.csv')\n","test_data = pd.read_csv('data/test.csv')\n","train_data.describe(include='all')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["size_train = len(train_data)\n","dataset = pd.concat([train_data, test_data]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"PassengerId       0\nSurvived        418\nPclass            0\nName              0\nSex               0\nAge             263\nSibSp             0\nParch             0\nTicket            0\nFare              1\nCabin          1014\nEmbarked          2\ndtype: int64"},"metadata":{},"execution_count":4}],"source":["dataset.isna().sum()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"      PassengerId  Survived  Pclass  \\\n74             75       1.0       3   \n5               6       0.0       3   \n368           369       1.0       3   \n203           204       0.0       3   \n767           768       0.0       3   \n2               3       1.0       3   \n1269         1270       NaN       1   \n225           226       0.0       3   \n194           195       1.0       1   \n221           222       0.0       2   \n1229         1230       NaN       2   \n370           371       1.0       1   \n472           473       1.0       2   \n588           589       0.0       3   \n560           561       0.0       3   \n449           450       1.0       1   \n1127         1128       NaN       1   \n483           484       1.0       3   \n1037         1038       NaN       1   \n1113         1114       NaN       2   \n\n                                           Name     Sex   Age  SibSp  Parch  \\\n74                                Bing, Mr. Lee    male  32.0      0      0   \n5                              Moran, Mr. James    male   NaN      0      0   \n368                         Jermyn, Miss. Annie  female   NaN      0      0   \n203                        Youseff, Mr. Gerious    male  45.5      0      0   \n767                          Mangan, Miss. Mary  female  30.5      0      0   \n2                        Heikkinen, Miss. Laina  female  26.0      0      0   \n1269                Hipkins, Mr. William Edward    male  55.0      0      0   \n225                Berglund, Mr. Karl Ivar Sven    male  22.0      0      0   \n194   Brown, Mrs. James Joseph (Margaret Tobin)  female  44.0      0      0   \n221                        Bracken, Mr. James H    male  27.0      0      0   \n1229                       Denbury, Mr. Herbert    male  25.0      0      0   \n370                 Harder, Mr. George Achilles    male  25.0      1      0   \n472     West, Mrs. Edwy Arthur (Ada Mary Worth)  female  33.0      1      2   \n588                       Gilinski, Mr. Eliezer    male  22.0      0      0   \n560                    Morrow, Mr. Thomas Rowan    male   NaN      0      0   \n449              Peuchen, Major. Arthur Godfrey    male  52.0      0      0   \n1127                   Warren, Mr. Frank Manley    male  64.0      1      0   \n483                      Turkula, Mrs. (Hedwig)  female  63.0      0      0   \n1037                Hilliard, Mr. Herbert Henry    male   NaN      0      0   \n1113                 Cook, Mrs. (Selena Rogers)  female  22.0      0      0   \n\n                Ticket     Fare Cabin Embarked  \n74                1601  56.4958   NaN        S  \n5               330877   8.4583   NaN        Q  \n368              14313   7.7500   NaN        Q  \n203               2628   7.2250   NaN        C  \n767             364850   7.7500   NaN        Q  \n2     STON/O2. 3101282   7.9250   NaN        S  \n1269               680  50.0000   C39        S  \n225            PP 4348   9.3500   NaN        S  \n194           PC 17610  27.7208    B4        C  \n221             220367  13.0000   NaN        S  \n1229        C.A. 31029  31.5000   NaN        S  \n370              11765  55.4417   E50        C  \n472         C.A. 34651  27.7500   NaN        S  \n588              14973   8.0500   NaN        S  \n560             372622   7.7500   NaN        Q  \n449             113786  30.5000  C104        S  \n1127            110813  75.2500   D37        C  \n483               4134   9.5875   NaN        S  \n1037             17463  51.8625   E46        S  \n1113       W./C. 14266  10.5000   F33        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>74</th>\n      <td>75</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Bing, Mr. Lee</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1601</td>\n      <td>56.4958</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>369</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Jermyn, Miss. Annie</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14313</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>204</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Youseff, Mr. Gerious</td>\n      <td>male</td>\n      <td>45.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2628</td>\n      <td>7.2250</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>768</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Mangan, Miss. Mary</td>\n      <td>female</td>\n      <td>30.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>364850</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1269</th>\n      <td>1270</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Hipkins, Mr. William Edward</td>\n      <td>male</td>\n      <td>55.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>680</td>\n      <td>50.0000</td>\n      <td>C39</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>226</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Berglund, Mr. Karl Ivar Sven</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PP 4348</td>\n      <td>9.3500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>195</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Brown, Mrs. James Joseph (Margaret Tobin)</td>\n      <td>female</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17610</td>\n      <td>27.7208</td>\n      <td>B4</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>222</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>Bracken, Mr. James H</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>220367</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1229</th>\n      <td>1230</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>Denbury, Mr. Herbert</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C.A. 31029</td>\n      <td>31.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>370</th>\n      <td>371</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Harder, Mr. George Achilles</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11765</td>\n      <td>55.4417</td>\n      <td>E50</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>473</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>West, Mrs. Edwy Arthur (Ada Mary Worth)</td>\n      <td>female</td>\n      <td>33.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C.A. 34651</td>\n      <td>27.7500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>589</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Gilinski, Mr. Eliezer</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14973</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>561</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Morrow, Mr. Thomas Rowan</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>372622</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>450</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Peuchen, Major. Arthur Godfrey</td>\n      <td>male</td>\n      <td>52.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113786</td>\n      <td>30.5000</td>\n      <td>C104</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1127</th>\n      <td>1128</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Warren, Mr. Frank Manley</td>\n      <td>male</td>\n      <td>64.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>110813</td>\n      <td>75.2500</td>\n      <td>D37</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>484</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Turkula, Mrs. (Hedwig)</td>\n      <td>female</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4134</td>\n      <td>9.5875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>1038</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Hilliard, Mr. Herbert Henry</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1113</th>\n      <td>1114</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>Cook, Mrs. (Selena Rogers)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>W./C. 14266</td>\n      <td>10.5000</td>\n      <td>F33</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":5}],"source":["dataset.sample(20)"]},{"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["EDA = False"]},{"cell_type":"markdown","metadata":{},"source":["### Age"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["if EDA:\n","    ax = sns.kdeplot(train_data.loc[train_data['Survived']==True, 'Age'], shade=True, color='r')\n","    ax = sns.kdeplot(train_data.loc[train_data['Survived']==False, 'Age'], shade=True, color='b', ax=ax)\n","    ax_legend = ax.legend(['Survived', 'Not Survived'])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["if EDA:\n","    g = sns.FacetGrid(data=train_data, col='Survived')\n","    g = g.map(sns.distplot, 'Age')"]},{"cell_type":"code","execution_count":9,"metadata":{"tags":[]},"outputs":[],"source":["if EDA:\n","    features = ['SibSp', 'Pclass', 'Sex', 'Parch', 'Embarked']\n","    for f in features:\n","        sns.catplot(x=f, y='Age', data=dataset, kind='box')\n","    sns.heatmap(dataset[features + ['Age']].corr(), annot=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.catplot(x='Pclass', y='Age', hue='Sex', data=dataset, kind='bar')"]},{"cell_type":"markdown","metadata":{},"source":["### Fare"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["if EDA:\n","    fig = plt.figure(figsize=[12, 4])\n","    axes = fig.subplots(1, 2)\n","    ax = sns.distplot(train_data['Fare'], ax=axes[0])\n","    ax = sns.distplot(train_data['Fare'].map(lambda x: np.log(x) if x > 0 else -10), ax=axes[1])"]},{"cell_type":"markdown","metadata":{},"source":["### Pclass"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["if EDA:\n","    g = sns.catplot(x='Pclass', y='Survived', hue='Sex', data=train_data, kind='bar')"]},{"cell_type":"markdown","metadata":{},"source":["### Embarked"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["if EDA:\n","    g = sns.catplot(x='Embarked', y='Survived', hue='Sex', data=train_data, kind='bar')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.catplot(x='Pclass', col='Embarked', data=train_data, kind='count')"]},{"cell_type":"markdown","metadata":{},"source":["### Family"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.catplot(x='SibSp', y='Survived', data=train_data, kind='bar')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.catplot(x='Parch', y='Survived', data=train_data, kind='bar')"]},{"cell_type":"markdown","metadata":{},"source":["### Sex"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.catplot(x='Sex', y='Survived', data=train_data, kind='bar')"]},{"cell_type":"markdown","metadata":{},"source":["## Data processing "]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"PassengerId       0\nSurvived        418\nPclass            0\nName              0\nSex               0\nAge             263\nSibSp             0\nParch             0\nTicket            0\nFare              1\nCabin          1014\nEmbarked          2\ndtype: int64"},"metadata":{},"execution_count":18}],"source":["dataset.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["### Age, Fare, Embarked"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["dataset['Embarked'].fillna('S', inplace=True)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"      PassengerId  Survived  Pclass                Name   Sex   Age  SibSp  \\\n1043         1044       NaN       3  Storey, Mr. Thomas  male  60.5      0   \n\n      Parch Ticket  Fare Cabin Embarked  \n1043      0   3701   NaN   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1043</th>\n      <td>1044</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Storey, Mr. Thomas</td>\n      <td>male</td>\n      <td>60.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3701</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":20}],"source":["dataset[dataset['Fare'].isnull()]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["dataset['Fare'].fillna(dataset.loc[(dataset['Pclass'] == 3) & (dataset['Embarked'] == 'S'), 'Fare'].median(), inplace=True)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["dataset['Age'] = dataset.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"PassengerId       0\nSurvived        418\nPclass            0\nName              0\nSex               0\nAge               0\nSibSp             0\nParch             0\nTicket            0\nFare              0\nCabin          1014\nEmbarked          0\ndtype: int64"},"metadata":{},"execution_count":23}],"source":["dataset.isnull().sum()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["dataset['AgeBand'] = pd.qcut(dataset['Age'], 10)\n","if EDA:\n","    sns.countplot(x='AgeBand', hue='Survived', data=dataset)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["dataset['FareBand'] = pd.qcut(dataset['Fare'], 13)\n","if EDA:\n","    sns.countplot(x='FareBand', hue='Survived', data=dataset)"]},{"cell_type":"markdown","metadata":{},"source":["### Cabin"]},{"cell_type":"code","execution_count":26,"metadata":{"tags":[]},"outputs":[],"source":["dataset['Cabin'] = dataset['Cabin'].str.extract(r'^(\\S)', expand=False).fillna('M')"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.catplot(x='Cabin', y='Survived', data=dataset.loc[:size_train], kind='bar')"]},{"cell_type":"code","execution_count":28,"metadata":{"tags":[]},"outputs":[],"source":["dataset['Cabin'].replace(['A', 'B', 'C', 'T'], 'ABC', inplace=True)\n","dataset['Cabin'].replace(['D', 'E'], 'DE', inplace=True)\n","dataset['Cabin'].replace(['F', 'G'], 'FG', inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Name"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"166                Chibnall, Mrs. (Edith Martha Bowerman)\n312                 Lahtinen, Mrs. William (Anna Sylfven)\n885                  Rice, Mrs. William (Margaret Norton)\n362                       Barbara, Mrs. (Catherine David)\n591       Stephenson, Mrs. Walter Bertram (Martha Eustis)\n1252              Mallet, Mrs. Albert (Antoinette Magnin)\n427     Phillips, Miss. Kate Florence (\"Mrs Kate Louis...\n1286       Smith, Mrs. Lucien Philip (Mary Eloise Hughes)\n254              Rosblom, Mrs. Viktor (Helena Wilhelmina)\n678               Goodwin, Mrs. Frederick (Augusta Tyler)\n40         Ahlin, Mrs. Johan (Johanna Persdotter Larsson)\n763             Carter, Mrs. William Ernest (Lucile Polk)\n995             Thomas, Mrs. Alexander (Thamine Thelma\")\"\n230          Harris, Mrs. Henry Birkhardt (Irene Wallach)\n1075    Douglas, Mrs. Frederick Charles (Mary Helene B...\n801           Collyer, Mrs. Harvey (Charlotte Annie Tate)\n432     Louch, Mrs. Charles Alexander (Alice Adelaide ...\n1005               Straus, Mrs. Isidor (Rosalie Ida Blun)\n726           Renouf, Mrs. Peter Henry (Lillian Jefferys)\n1288    Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...\nName: Name, dtype: object"},"metadata":{},"execution_count":29}],"source":["dataset.loc[dataset['Name'].str.contains('\\('), 'Name'].sample(20)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["dataset['Surname'] = dataset['Name'].str.extract(r'^([^,]+),', expand=False)\n","dataset['Title'] = dataset['Name'].str.extract(r'([A-Za-z]+)\\.', expand=False)\n","dataset['Title'].replace(['Ms', 'Mlle', 'Countess', 'Lady', 'Dona', 'Mme'], 'Miss', inplace=True)\n","dataset['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Rev', 'Don', 'Sir'], 'Noble', inplace=True)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.countplot(x='Title', hue='Survived', data=dataset[:size_train])"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n","if EDA:\n","    sns.countplot(x='FamilySize', hue='Survived', data=dataset)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["dataset.loc[dataset['FamilySize'] == 1, 'FamilyType'] = 'Alone'\n","dataset.loc[(dataset['FamilySize'] > 1) & (dataset['FamilySize'] < 5), 'FamilyType'] = 'Small'\n","dataset.loc[(dataset['FamilySize'] >= 5) & (dataset['FamilySize'] < 7), 'FamilyType'] = 'Small'\n","dataset['FamilyType'].fillna('Large', inplace=True)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["if EDA:\n","    sns.countplot(x='FamilyType', hue='Survived', data=dataset)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["surname_survived = dataset[:size_train].groupby('Surname')['Survived'].mean().to_dict()\n","surname_count = dataset[:size_train].groupby('Surname')['Survived'].count().to_dict()\n","surname_train = set(dataset.iloc[:size_train]['Surname'].tolist())\n","surname_test = set(dataset.iloc[size_train:]['Surname'].tolist())\n","\n","surname_set = surname_train.intersection(surname_test)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["average_mean = dataset['Survived'].mean()\n","dataset['SurnameSurvived'] = dataset['Surname'].transform(lambda x: surname_survived[x] if x in surname_set and surname_count[x] > 1 else average_mean)\n","dataset['SurnameSurvivedisNA'] = dataset['Surname'].transform(lambda x: 0 if x in surname_set and surname_count[x] > 1 else 1)"]},{"cell_type":"markdown","metadata":{},"source":["### Ticket"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# ticket_survived = dataset[:size_train].groupby('Ticket')['Survived'].mean().to_dict()\n","# ticket_count = dataset[:size_train].groupby('Ticket')['Survived'].count().to_dict()\n","# ticket_train = set(dataset.iloc[:size_train]['Ticket'].tolist())\n","# ticket_test = set(dataset.iloc[size_train:]['Ticket'].tolist())\n","\n","# ticket_set = ticket_train.intersection(ticket_test)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# dataset['TicketSurvived'] = dataset['Ticket'].transform(lambda x: ticket_survived[x] if x in ticket_set and ticket_count[x] > 1 else average_mean)\n","# dataset['TicketSurvivedisNA'] = dataset['Ticket'].transform(lambda x: 0 if x in ticket_set and ticket_count[x] > 1 else 1)\n","# dataset['TicketFreq'] = dataset.groupby('Ticket')['Ticket'].transform('count')"]},{"cell_type":"markdown","metadata":{},"source":["### Finalize"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["dataset.drop(['Name', 'Ticket', 'Surname', 'FamilySize', 'SibSp', 'Parch', 'Age', 'Fare'], axis='columns', inplace=True)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"      PassengerId  Survived  Pclass     Sex Cabin Embarked        AgeBand  \\\n870           871       0.0       3    male     M        S   (25.0, 26.0]   \n703           704       0.0       3    male     M        Q   (22.0, 25.0]   \n296           297       0.0       3    male     M        C   (22.0, 25.0]   \n408           409       0.0       3    male     M        S   (16.0, 21.0]   \n821           822       1.0       3    male     M        S   (26.0, 29.5]   \n1296         1297       NaN       2    male    DE        C   (16.0, 21.0]   \n1180         1181       NaN       3    male     M        S   (22.0, 25.0]   \n1174         1175       NaN       3  female     M        C  (0.169, 16.0]   \n1203         1204       NaN       3    male     M        S   (22.0, 25.0]   \n391           392       1.0       3    male     M        S   (16.0, 21.0]   \n\n            FareBand Title FamilyType  SurnameSurvived  SurnameSurvivedisNA  \n870    (7.75, 7.896]    Mr      Alone         0.383838                    1  \n703     (7.25, 7.75]    Mr      Alone         0.383838                    1  \n296   (-0.001, 7.25]    Mr      Alone         0.383838                    1  \n408    (7.75, 7.896]    Mr      Alone         0.383838                    1  \n821     (8.05, 10.5]    Mr      Alone         0.383838                    1  \n1296  (13.0, 15.742]    Mr      Alone         0.383838                    1  \n1180   (7.896, 8.05]    Mr      Alone         0.000000                    0  \n1174  (13.0, 15.742]  Miss      Small         0.383838                    1  \n1203    (7.25, 7.75]    Mr      Alone         0.383838                    1  \n391    (7.75, 7.896]    Mr      Alone         0.383838                    1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>AgeBand</th>\n      <th>FareBand</th>\n      <th>Title</th>\n      <th>FamilyType</th>\n      <th>SurnameSurvived</th>\n      <th>SurnameSurvivedisNA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>870</th>\n      <td>871</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>S</td>\n      <td>(25.0, 26.0]</td>\n      <td>(7.75, 7.896]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>703</th>\n      <td>704</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>Q</td>\n      <td>(22.0, 25.0]</td>\n      <td>(7.25, 7.75]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>297</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>C</td>\n      <td>(22.0, 25.0]</td>\n      <td>(-0.001, 7.25]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408</th>\n      <td>409</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>S</td>\n      <td>(16.0, 21.0]</td>\n      <td>(7.75, 7.896]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>822</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>S</td>\n      <td>(26.0, 29.5]</td>\n      <td>(8.05, 10.5]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>1297</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>male</td>\n      <td>DE</td>\n      <td>C</td>\n      <td>(16.0, 21.0]</td>\n      <td>(13.0, 15.742]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1180</th>\n      <td>1181</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>S</td>\n      <td>(22.0, 25.0]</td>\n      <td>(7.896, 8.05]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1174</th>\n      <td>1175</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>female</td>\n      <td>M</td>\n      <td>C</td>\n      <td>(0.169, 16.0]</td>\n      <td>(13.0, 15.742]</td>\n      <td>Miss</td>\n      <td>Small</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>1204</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>S</td>\n      <td>(22.0, 25.0]</td>\n      <td>(7.25, 7.75]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>392</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>M</td>\n      <td>S</td>\n      <td>(16.0, 21.0]</td>\n      <td>(7.75, 7.896]</td>\n      <td>Mr</td>\n      <td>Alone</td>\n      <td>0.383838</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":40}],"source":["dataset.sample(10)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","dataset = pd.get_dummies(dataset, columns=['Pclass'])\n","dataset = pd.get_dummies(dataset, columns=['FamilyType'])\n","dataset = pd.get_dummies(dataset, columns=['Cabin'])\n","dataset = pd.get_dummies(dataset, columns=['Embarked'])\n","dataset = pd.get_dummies(dataset, columns=['Title'])\n","dataset['Sex'] = LabelEncoder().fit_transform(dataset['Sex'])\n","dataset['AgeBand'] = LabelEncoder().fit_transform(dataset['AgeBand'])\n","dataset['FareBand'] = LabelEncoder().fit_transform(dataset['FareBand'])"]},{"cell_type":"markdown","metadata":{},"source":["## Start training"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":43,"metadata":{"tags":[]},"outputs":[],"source":["y = dataset.iloc[:size_train]['Survived']\n","X = dataset.iloc[:size_train].drop(columns=['Survived', 'PassengerId'], axis=1)\n","X_test = dataset.iloc[size_train:].drop(columns=['Survived', 'PassengerId'], axis=1)\n","y_test = pd.read_csv('data/test_label.csv')['Survived']"]},{"cell_type":"code","execution_count":53,"metadata":{"tags":[]},"outputs":[],"source":["model = RandomForestClassifier(n_estimators=400, max_depth=5, random_state=47, n_jobs=-1, verbose=1)\n","model.fit(X, y)\n","y_pred = model.predict(X_test).astype(np.int)\n","results = pd.DataFrame({'PassengerId': dataset.iloc[size_train:]['PassengerId'], 'Survived': y_pred})\n","results.to_csv('submission_0806_rf.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Finish"]},{"cell_type":"code","execution_count":54,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"0.7799043062200957\n"}],"source":["score = accuracy_score(y_test, y_pred)\n","print(score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"},"orig_nbformat":2,"kernelspec":{"name":"python38364bitkaggleconda23a741be085945aa888cbd21aa05de81","display_name":"Python 3.8.3 64-bit ('kaggle': conda)"}}}